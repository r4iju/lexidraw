<!-- f0cc4361-cba4-4b3f-8a11-6f222a701e17 ea7b9bb0-fd41-47e6-8f02-7a1feba4ea49 -->
# TTS for Articles/URLs (Phase 1), extensible to Documents (Phase 2)

## Goals

- Convert article/URL content to high‑quality audio with OpenAI and/or Google, selectable at runtime.
- Offer streaming playback for shorter items; background job for long items. Cache results for reuse.
- Cleanly extend to document inputs (PDF/DOCX) later without rework.

## Provider capabilities snapshot (2025)

- OpenAI: natural voices; strong steerability; good latency; limited/implicit SSML; realtime streaming possible via Realtime API; per‑request input limits → chunking required.
- Google Cloud TTS: broad language/voice coverage; first‑class SSML (breaks, prosody); long‑form via chunking/asynchronous patterns; per‑million‑character pricing; robust reliability.

## Architecture (Phase 1)

- Provider abstraction: a single interface hides provider specifics (voices, SSML support, limits).
- Pipeline: fetch → extract main content → normalize → chunk → synthesize per chunk → stitch → store → stream/play.
- Storage & caching: content‑hash key to dedupe; serve from CDN; configurable TTL.
- Observability: per‑segment timings, error tags, provider spend estimates.

## File layout (apps/lexidraw)

- `src/lib/extract-article.ts`: fetch HTML, JSDOM + `@mozilla/readability`, sanitize.
- `src/lib/chunk-text.ts`: semantic chunking by headings/paragraphs; target ~1–2k chars.
- `src/lib/ssml.ts`: build SSML (Google only) with `<p>`, `<break/>`, optional `<prosody/>`.
- `src/server/tts/types.ts`: shared types (request, segment, provider enums).
- `src/server/tts/providers/openai.ts`: OpenAI synth; natural‑language style controls; mp3/pcm.
- `src/server/tts/providers/google.ts`: Google synth; SSML; mp3/ogg; voice map.
- `src/server/tts/engine.ts`: provider selection, chunk loop, stitching, storage.
- `src/app/api/tts/route.ts`: POST create job by url/text; GET by jobId for status/audio; optional streaming.
- `src/components/audio/ArticleAudioPlayer.tsx`: simple player with chapter markers; shadcn UI.
- Types reused in `packages/types` as needed; env wired via `packages/env`.

## Provider abstraction

```ts
// Minimal new code for clarity
export interface TtsProvider {
  name: 'openai' | 'google';
  maxCharsPerRequest: number;
  supportsSsml: boolean;
  synthesize(input: {
    textOrSsml: string;
    voiceId: string;
    speed?: number;
    format: 'mp3' | 'ogg' | 'wav';
    sampleRate?: number;
    metadata?: Record<string, string>;
  }): Promise<{ audio: Buffer; durationSec?: number }>; // one chunk
}
```

## Flow (Phase 1)

1. Input: `POST /api/tts` with `{ url | text, provider?, voice?, speed?, format? }`.
2. Extraction (if url): fetch HTML server‑side; Readability to main content; strip boilerplate.
3. Normalization: collapse whitespace, preserve headings/paragraphs; language detect if needed.
4. Chunking: split by headings/paragraphs; constrain to provider `maxCharsPerRequest`; maintain chapter index.
5. Synthesis per chunk:

   - Google: build SSML with `<p>` per paragraph and timed `<break time="300ms"/>` between.
   - OpenAI: plain text with style prompt; add punctuation/hard breaks between paragraphs.

6. Stitching: transcode/concat to target format/bitrate; inject chapter metadata.
7. Storage: write to object storage (Vercel Blob or S3/GCS); key = hash(url/text + provider + voice + params).
8. Response: return job record with audio URL(s), chapters, durations. For small items, optionally stream as produced.

## Provider selection strategy

- Language/voice coverage: prefer Google for non‑English or specific locales; otherwise either.
- SSML needs (precise pacing, prosody): prefer Google.
- Latency/interactive: prefer OpenAI for faster, conversational style, or use Realtime for live.
- Cost guardrails: configurable per‑provider limits and price weights; choose cheapest meeting constraints.
- Fallback: if provider fails a chunk, retry then switch provider (with format parity).

## Limits & chunk sizes (practical defaults)

- Target chunk ~1,200–1,800 chars; hard cap ~4,000 chars (provider dependent).
- Pace: default 1.0×; allow 0.85–1.2× via provider options.
- Format: `mp3`, 22050–24000 Hz, CBR 128 kbps. Keep consistent across chunks.

## Storage & caching

- Prefer Vercel Blob for simplicity in Next; or S3/GCS if already in infra.
- Cache index in DB/KV keyed by content hash; invalidate when source changes.
- Set public CDN caching headers; pre‑sign private URLs if needed.

## Frontend

- `ArticleAudioPlayer`: shows title, duration, and chapter list (from chunk boundaries).
- Progressive enhancement: play while remaining chunks synthesize (if stream enabled).
- Use shadcn components; no global CSS changes.

## Observability & cost controls

- Log per‑chunk timings, bytes, provider; aggregate in traces.
- Budget guard: estimate chars × provider price; reject or warn if over threshold.
- Alert on error rates, retries, and stitching failures.

## Security & compliance

- Credentials: Resolve provider and API key from the signed‑in user's LLM configuration at request time; fallback to org/global keys via `packages/env` if absent. Keys stay server‑side only, encrypted at rest, never sent to the client, and redacted in logs.
- Respect robots.txt/ToS; avoid paywalled content unless authorized.
- Sanitize HTML; remove scripts/trackers before processing.
- PII guardrails if content includes personal data.

## Phase 2 (Documents)

- Add `src/lib/extract-document.ts`: PDF via `pdf-parse` or `pdfjs-dist`; DOCX via `docx` or `mammoth`.
- Preserve headings; same chunking/SSML.
- For very long docs, run as background job (queue + webhook/polling GET endpoint) and email/notify when ready.

## Rollout

- Pilot with English; 3–5 voices; compare OpenAI vs Google on a sample set; choose defaults.
- Add streaming for short articles; queue for long‑form; ship cost dashboard.

## Notes on pricing

- Prices change frequently; keep configurable. Implement a pricing table in config and a cost estimator per request.

### To-dos

- [ ] Define TTS types and provider interface in src/server/tts/types.ts
- [ ] Implement Readability-based article extractor in src/lib/extract-article.ts
- [ ] Implement heading/paragraph-aware chunker in src/lib/chunk-text.ts
- [ ] Build minimal SSML generator for Google in src/lib/ssml.ts
- [ ] Implement OpenAI provider synth in src/server/tts/providers/openai.ts
- [ ] Implement Google provider synth with SSML in src/server/tts/providers/google.ts
- [ ] Create synthesis engine to select provider, loop chunks, stitch, and store
- [ ] Add POST/GET /api/tts route handlers for job create/status in app layer
- [ ] Wire storage (Vercel Blob/S3) and content-hash caching for audio outputs
- [ ] Build ArticleAudioPlayer with chapters using shadcn components
- [ ] Add logging, metrics, and cost estimation with configurable thresholds
- [ ] Add PDF/DOCX extractors and long-job execution path